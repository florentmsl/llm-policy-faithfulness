You need to help a user analyze a control policy for a reinforcement learning task.
The policy is obtained with deep reinforcement learning.
You need to first understand the goal of the task and the policy.

# Task Description
{{#ENV_DESCRIPTION}}
Environment:
{{ENV_DESCRIPTION}}
{{/ENV_DESCRIPTION}}

{{#TASK_DESCRIPTION}}
Task objective:
{{TASK_DESCRIPTION}}
{{/TASK_DESCRIPTION}}

{{#REWARD_FUNCTION}}
Reward function used during training:
```python
{{REWARD_FUNCTION}}
```
{{/REWARD_FUNCTION}}

# The Policy
Here is the symbolic policy obtained after training:
```python
{{SYMBOLIC_POLICY}}
```

{{#IN_CONTEXT_LEARNING_EXAMPLE}}
# Example (only for reference)
Here is an example of how to analyze and explain a symbolic policy (only for reference):
{{IN_CONTEXT_LEARNING_EXAMPLE}}
{{/IN_CONTEXT_LEARNING_EXAMPLE}}

# Your Task
Explain what this policy does in the environment.

# Answer Rules
- The explanation must be specific and concrete.
- Trace the program flow in execution order (which conditions are checked, which branches are taken, and which actions are returned).
- Your explanations should be entirely based on the policy.
